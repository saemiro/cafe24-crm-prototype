{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ Cafe24 CRM Fine-tuning & A/B/C ì‹¤í—˜\n",
        "\n",
        "**ë°œí‘œìš© ë°ì´í„° ìƒì„± ë…¸íŠ¸ë¶**\n",
        "\n",
        "1. Llama 3 8B QLoRA Fine-tuning (ë¬´ë£Œ T4 GPU)\n",
        "2. A/B/C ë¹„êµ ì‹¤í—˜ ì‹¤í–‰\n",
        "3. ê²°ê³¼ JSON ë‹¤ìš´ë¡œë“œ\n",
        "\n",
        "â±ï¸ **ì˜ˆìƒ ì‹œê°„: 30-40ë¶„**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0ï¸âƒ£ GPU í™•ì¸ & ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU í™•ì¸\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unsloth ì„¤ì¹˜ (ë¹ ë¥¸ fine-tuning)\n",
        "%%capture\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps trl peft accelerate bitsandbytes triton\n",
        "!pip install datasets huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1ï¸âƒ£ í•™ìŠµ ë°ì´í„° ì—…ë¡œë“œ\n",
        "\n",
        "**ğŸ‘† ì™¼ìª½ íŒŒì¼ ì•„ì´ì½˜ í´ë¦­ â†’ `cafe24_finetuning_dataset.jsonl` ì—…ë¡œë“œ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# íŒŒì¼ ì—…ë¡œë“œ (ìˆ˜ë™)\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# ì´ë¯¸ ì—…ë¡œë“œí–ˆìœ¼ë©´ ìŠ¤í‚µ\n",
        "if not os.path.exists('cafe24_finetuning_dataset.jsonl'):\n",
        "    print(\"ğŸ“ cafe24_finetuning_dataset.jsonl íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”!\")\n",
        "    uploaded = files.upload()\n",
        "else:\n",
        "    print(\"âœ… ë°ì´í„° íŒŒì¼ í™•ì¸ë¨!\")\n",
        "\n",
        "# ë°ì´í„° í™•ì¸\n",
        "!wc -l cafe24_finetuning_dataset.jsonl\n",
        "!head -1 cafe24_finetuning_dataset.jsonl | python -m json.tool | head -20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2ï¸âƒ£ ëª¨ë¸ ë¡œë“œ (Llama 3 8B + QLoRA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# ëª¨ë¸ ì„¤ì •\n",
        "max_seq_length = 2048\n",
        "dtype = None  # auto\n",
        "load_in_4bit = True  # QLoRA (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
        "\n",
        "# Llama 3 8B ë¡œë“œ\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        ")\n",
        "\n",
        "print(\"âœ… Llama 3 8B ë¡œë“œ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LoRA ì„¤ì •\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,  # LoRA rank\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"âœ… LoRA ì ìš© ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3ï¸âƒ£ ë°ì´í„°ì…‹ ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# JSONL ë¡œë“œ\n",
        "dataset = load_dataset('json', data_files='cafe24_finetuning_dataset.jsonl', split='train')\n",
        "print(f\"ğŸ“Š í•™ìŠµ ë°ì´í„°: {len(dataset)}ê°œ\")\n",
        "\n",
        "# ChatML í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "def format_prompts(examples):\n",
        "    texts = []\n",
        "    for messages in examples['messages']:\n",
        "        text = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=False\n",
        "        )\n",
        "        texts.append(text)\n",
        "    return {\"text\": texts}\n",
        "\n",
        "dataset = dataset.map(format_prompts, batched=True)\n",
        "print(\"âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4ï¸âƒ£ Fine-tuning ì‹¤í–‰ (ì•½ 15-20ë¶„)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        max_steps=60,  # ë¹ ë¥¸ í•™ìŠµ (ë°ëª¨ìš©)\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not torch.cuda.is_bf16_supported(),\n",
        "        bf16=torch.cuda.is_bf16_supported(),\n",
        "        logging_steps=10,\n",
        "        optim=\"adamw_8bit\",\n",
        "        output_dir=\"outputs\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(\"ğŸš€ Fine-tuning ì‹œì‘...\")\n",
        "trainer_stats = trainer.train()\n",
        "print(\"âœ… Fine-tuning ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5ï¸âƒ£ A/B/C ë¹„êµ ì‹¤í—˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸\n",
        "TEST_PROMPTS = [\n",
        "    {\n",
        "        \"id\": \"customer_lookup\",\n",
        "        \"prompt\": \"Cafe24 ê³ ê° ì¡°íšŒ APIë¥¼ ì‚¬ìš©í•´ì„œ íŠ¹ì • ê³ ê°ì˜ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤˜.\",\n",
        "        \"expected\": [\"customers\", \"GET\", \"member_id\", \"API\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"order_status\",\n",
        "        \"prompt\": \"ì£¼ë¬¸ ìƒíƒœë¥¼ ë³€ê²½í•˜ëŠ” API í˜¸ì¶œ ì½”ë“œë¥¼ Pythonìœ¼ë¡œ ì‘ì„±í•´ì¤˜.\",\n",
        "        \"expected\": [\"orders\", \"PUT\", \"order_id\", \"status\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"product_inventory\",\n",
        "        \"prompt\": \"ìƒí’ˆ ì¬ê³ ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” API ì‚¬ìš©ë²•ì„ ì„¤ëª…í•´ì¤˜.\",\n",
        "        \"expected\": [\"products\", \"variants\", \"stock\", \"quantity\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"coupon_create\",\n",
        "        \"prompt\": \"VIP ê³ ê°ì—ê²Œ ì¿ í°ì„ ë°œê¸‰í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ì¤˜.\",\n",
        "        \"expected\": [\"coupons\", \"member\", \"POST\", \"discount\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"mileage_add\",\n",
        "        \"prompt\": \"ê³ ê°ì—ê²Œ ì ë¦½ê¸ˆì„ ì§€ê¸‰í•˜ëŠ” API í˜¸ì¶œ ë°©ë²•ì„ ì•Œë ¤ì¤˜.\",\n",
        "        \"expected\": [\"mileage\", \"point\", \"member\", \"POST\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
        "SYSTEM_PROMPTS = {\n",
        "    \"A\": \"\"\"ë‹¹ì‹ ì€ Cafe24 CRM API ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "ë‹¤ìŒ ì˜¨í†¨ë¡œì§€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì„¸ìš”:\n",
        "- Customer: ê³ ê° ì •ë³´ (PLACES â†’ Order, HAS_ADDRESS â†’ Address)\n",
        "- Order: ì£¼ë¬¸ ì •ë³´ (CONTAINS â†’ OrderItem, PAID_BY â†’ Payment)\n",
        "- Product: ìƒí’ˆ ì •ë³´ (BELONGS_TO â†’ Category)\n",
        "- Campaign: ë§ˆì¼€íŒ… ìº í˜ì¸ (TARGETS â†’ CustomerSegment)\n",
        "API ë² ì´ìŠ¤: https://{mall_id}.cafe24api.com/api/v2/admin\"\"\",\n",
        "    \n",
        "    \"B\": \"ë‹¹ì‹ ì€ Cafe24 CRM API ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\",  # Fine-tuned (í•™ìŠµëœ ì§€ì‹ ì‚¬ìš©)\n",
        "    \n",
        "    \"C\": \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"  # Vanilla\n",
        "}\n",
        "\n",
        "print(\"âœ… í…ŒìŠ¤íŠ¸ ì„¤ì • ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "def generate_response(system_prompt, user_prompt):\n",
        "    \"\"\"ëª¨ë¸ ì‘ë‹µ ìƒì„±\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "    \n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(\"cuda\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    latency = (time.time() - start_time) * 1000\n",
        "    \n",
        "    response = tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n",
        "    return response, latency\n",
        "\n",
        "def score_response(response, expected):\n",
        "    \"\"\"ì‘ë‹µ ì ìˆ˜ ê³„ì‚°\"\"\"\n",
        "    response_lower = response.lower()\n",
        "    found = sum(1 for e in expected if e.lower() in response_lower)\n",
        "    relevance = found / len(expected) if expected else 0\n",
        "    \n",
        "    accuracy_signals = [\n",
        "        \"http\" in response_lower or \"api\" in response_lower,\n",
        "        \"```\" in response,\n",
        "        \"def \" in response or \"function\" in response_lower,\n",
        "        \"cafe24\" in response_lower\n",
        "    ]\n",
        "    accuracy = sum(accuracy_signals) / len(accuracy_signals)\n",
        "    \n",
        "    return relevance, accuracy\n",
        "\n",
        "print(\"âœ… ì¶”ë¡  í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A/B/C ì‹¤í—˜ ì‹¤í–‰\n",
        "results = []\n",
        "\n",
        "print(\"ğŸ§ª A/B/C ì‹¤í—˜ ì‹œì‘...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for test in TEST_PROMPTS:\n",
        "    print(f\"\\nğŸ“‹ í…ŒìŠ¤íŠ¸: {test['id']}\")\n",
        "    \n",
        "    for approach in [\"A\", \"B\", \"C\"]:\n",
        "        print(f\"  â†’ ì ‘ê·¼ë²• {approach} ì‹¤í–‰ ì¤‘...\", end=\" \")\n",
        "        \n",
        "        try:\n",
        "            response, latency = generate_response(\n",
        "                SYSTEM_PROMPTS[approach],\n",
        "                test[\"prompt\"]\n",
        "            )\n",
        "            relevance, accuracy = score_response(response, test[\"expected\"])\n",
        "            \n",
        "            result = {\n",
        "                \"approach\": approach,\n",
        "                \"approach_name\": {\"A\": \"Ontology+Context\", \"B\": \"Fine-tuned\", \"C\": \"Vanilla\"}[approach],\n",
        "                \"prompt_id\": test[\"id\"],\n",
        "                \"prompt\": test[\"prompt\"],\n",
        "                \"response\": response[:1000],  # ì €ì¥ìš© truncate\n",
        "                \"latency_ms\": round(latency, 2),\n",
        "                \"relevance_score\": round(relevance, 3),\n",
        "                \"accuracy_score\": round(accuracy, 3),\n",
        "                \"combined_score\": round(relevance * 0.6 + accuracy * 0.4, 3),\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "            results.append(result)\n",
        "            \n",
        "            print(f\"âœ… (ê´€ë ¨ì„±: {relevance:.0%}, ì •í™•ë„: {accuracy:.0%})\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
        "            results.append({\n",
        "                \"approach\": approach,\n",
        "                \"prompt_id\": test[\"id\"],\n",
        "                \"error\": str(e)\n",
        "            })\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… ì‹¤í—˜ ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6ï¸âƒ£ ê²°ê³¼ ë¶„ì„ & ì €ì¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì ‘ê·¼ë²•ë³„ ì§‘ê³„\n",
        "print(\"\\nğŸ“Š ì‹¤í—˜ ê²°ê³¼ ìš”ì•½\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "report = {\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"total_tests\": len(results),\n",
        "    \"approaches\": {}\n",
        "}\n",
        "\n",
        "for approach in [\"A\", \"B\", \"C\"]:\n",
        "    approach_results = [r for r in results if r.get(\"approach\") == approach and \"error\" not in r]\n",
        "    \n",
        "    if approach_results:\n",
        "        avg_latency = sum(r[\"latency_ms\"] for r in approach_results) / len(approach_results)\n",
        "        avg_relevance = sum(r[\"relevance_score\"] for r in approach_results) / len(approach_results)\n",
        "        avg_accuracy = sum(r[\"accuracy_score\"] for r in approach_results) / len(approach_results)\n",
        "        avg_combined = sum(r[\"combined_score\"] for r in approach_results) / len(approach_results)\n",
        "        \n",
        "        name = {\"A\": \"Ontology+Context\", \"B\": \"Fine-tuned\", \"C\": \"Vanilla\"}[approach]\n",
        "        \n",
        "        report[\"approaches\"][approach] = {\n",
        "            \"name\": name,\n",
        "            \"avg_latency_ms\": round(avg_latency, 2),\n",
        "            \"avg_relevance\": round(avg_relevance, 3),\n",
        "            \"avg_accuracy\": round(avg_accuracy, 3),\n",
        "            \"avg_combined\": round(avg_combined, 3),\n",
        "            \"test_count\": len(approach_results)\n",
        "        }\n",
        "        \n",
        "        print(f\"\\n{approach}: {name}\")\n",
        "        print(f\"  í‰ê·  ì‘ë‹µì‹œê°„: {avg_latency:.0f}ms\")\n",
        "        print(f\"  ê´€ë ¨ì„± ì ìˆ˜: {avg_relevance:.1%}\")\n",
        "        print(f\"  ì •í™•ë„ ì ìˆ˜: {avg_accuracy:.1%}\")\n",
        "        print(f\"  ì¢…í•© ì ìˆ˜: {avg_combined:.1%}\")\n",
        "\n",
        "# ìš°ìŠ¹ì ê²°ì •\n",
        "scores = {k: v[\"avg_combined\"] for k, v in report[\"approaches\"].items()}\n",
        "winner = max(scores, key=scores.get)\n",
        "report[\"winner\"] = winner\n",
        "report[\"winner_name\"] = report[\"approaches\"][winner][\"name\"]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"ğŸ† ìš°ìŠ¹: {winner} ({report['winner_name']}) - ì¢…í•© {scores[winner]:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê²°ê³¼ ì €ì¥\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# ìƒì„¸ ê²°ê³¼\n",
        "results_file = f\"abc_results_{timestamp}.json\"\n",
        "with open(results_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# ìš”ì•½ ë¦¬í¬íŠ¸\n",
        "report_file = f\"abc_report_{timestamp}.json\"\n",
        "with open(report_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(report, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\nğŸ“ ì €ì¥ ì™„ë£Œ:\")\n",
        "print(f\"  - {results_file}\")\n",
        "print(f\"  - {report_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "from google.colab import files\n",
        "\n",
        "print(\"ğŸ“¥ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ:\")\n",
        "files.download(results_file)\n",
        "files.download(report_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… ì™„ë£Œ!\n",
        "\n",
        "ë‹¤ìš´ë¡œë“œëœ íŒŒì¼:\n",
        "- `abc_results_*.json` - ìƒì„¸ ì‹¤í—˜ ê²°ê³¼\n",
        "- `abc_report_*.json` - ìš”ì•½ ë¦¬í¬íŠ¸\n",
        "\n",
        "ì´ íŒŒì¼ë“¤ì„ `/Users/admin/cafe24-crm-prototype/experiments/` ì— ì €ì¥í•˜ì„¸ìš”."
      ]
    }
  ]
}
